{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ea8d9837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "x = torch.FloatTensor([[1,2],\n",
    "                       [3,4],\n",
    "                       [5,6]])\n",
    "\n",
    "y = torch.FloatTensor([[1,2],\n",
    "                       [1,2]])\n",
    "\n",
    "print(x.size(),y.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba4dda9",
   "metadata": {},
   "source": [
    "내적 규칙 : x의 열 수(2) == y의 행 수(2)\n",
    "z = torch.matmul(x,y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "013e51cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 내적 규칙 : x의 열 수(2) == y의 행 수(2)\n",
    "z = torch.matmul(x,y)\n",
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "30c7b061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 2]) torch.Size([3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "x = torch.FloatTensor([[[1,2],\n",
    "                       [3,4],\n",
    "                       [5,6]],\n",
    "                      \n",
    "                      [[7,8],\n",
    "                       [9,10],\n",
    "                       [11,12]],\n",
    "                      \n",
    "                      [[13,14],\n",
    "                       [15,16],\n",
    "                       [17,18]]])\n",
    "y = torch.FloatTensor([[[1,2,2],\n",
    "                       [1,2,2]],\n",
    "                      \n",
    "                      [[1,3,3],\n",
    "                       [1,3,3]],\n",
    "                      \n",
    "                      [[1,4,4],\n",
    "                       [1,4,4]]])\n",
    "\n",
    "print(x.size(),y.size())\n",
    "# 332 , 323\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d259ca",
   "metadata": {},
   "source": [
    "- 마지막 2개 차원을 기준으로 행렬곱 수행\n",
    "- batch 차원은 같아야 한다.( 아니면 1이라도 돼서 브로드캐스팅이라도 되어야 한다.)\n",
    "3,3,2 x 3,2,3 = 3x3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6ca0435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 3차원에서만 사용할 수 있는 행렬곱 연산 bmm(batch matrix multiplication)\n",
    "z = torch.bmm(x,y)  # 행렬 곱 수행 (마지막 2차원 기준)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e174d996",
   "metadata": {},
   "source": [
    "torch.bmm\n",
    "입력이 반드시 3차원 텐서 (B, N, N) @ (B, M, P) = (B, N, P)\n",
    "각 batch는 batch마다 독립적으로 행렬곱 연산\n",
    "\n",
    "\n",
    "| 구분      | torch.manmul              | torch.bmm               |\n",
    "|-----------|---------------------------|-------------------------|\n",
    "| 입력차원  | 1D~ND                     | 3D만                    |\n",
    "| batch 처리| 자동 해석 + 브로드캐스팅  | batch 크기 동일해야한다 |\n",
    "| 연산 범위 | 범용 행렬곱               | 배치 행렬곱             |\n",
    "| 유연성    | 높다                      | 낮다                    |\n",
    "\n",
    " bmm은 3차원 배치 행렬곱 전용\n",
    " matual은 차원 수에 따라 자동으로 처리되는 범용 행렬곱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49bb706",
   "metadata": {},
   "source": [
    ".T ( 전치 ) : 를 이용해서 입력 차원과 곱셈이 가능하도록 맞춘다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "100cb0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2, 3]])\n",
    "W = torch.tensor([[0.1, 0.2, 0.3],\n",
    "                  [0.4, 0.5, 0.6]])\n",
    "\n",
    "# 1행3열, 2행3열\n",
    "print(x.size(), W.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "35531869",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x3 and 2x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[100]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (1x3 and 2x3)"
     ]
    }
   ],
   "source": [
    "torch.matmul(x,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e22ad26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.T.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076fdc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4000, 3.2000]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.matmul(x,W.T)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0d99a8",
   "metadata": {},
   "source": [
    "행렬곱 절대원칙\n",
    "행렬곱에서 마지막 두차원은 만드시 아래와 같아야한다.\n",
    "(..., N, M) @ (..., M, P) => M == M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3540df93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 2]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[[1,2],\n",
    "                       [3,4],\n",
    "                       [5,6]],\n",
    "                      \n",
    "                      [[7,8],\n",
    "                       [9,10],\n",
    "                       [11,12]],\n",
    "                      \n",
    "                      [[13,14],\n",
    "                       [15,16],\n",
    "                       [17,18]]])\n",
    "\n",
    "W = torch.tensor([[0.1, 0.2, 0.3],\n",
    "                  [0.4, 0.5, 0.6]])\n",
    "\n",
    "print(x.size(),W.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2984a20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x,W)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2c4f90",
   "metadata": {},
   "source": [
    "```\n",
    "브로드캐스팅 (2,3) -> batch 차원 추가 (1,2,3) -> batch 방향으로 복제 -> (3,2,3)\n",
    "(3,3,2) @ (3,2,3) => (3,3,3) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb36e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 2]) torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[[1,2],\n",
    "                       [3,4],\n",
    "                       [5,6]],\n",
    "                      \n",
    "                      [[7,8],\n",
    "                       [9,10],\n",
    "                       [11,12]],\n",
    "                      \n",
    "                      [[13,14],\n",
    "                       [15,16],\n",
    "                       [17,18]]])\n",
    "\n",
    "W = torch.FloatTensor([[[0.1, 0.2, 0.3],\n",
    "                   [0.4, 0.5, 0.6]],\n",
    "                  \n",
    "                  [[0.1, 0.2, 0.3],\n",
    "                   [0.4, 0.5, 0.6]],\n",
    "                  \n",
    "                  [[0.1, 0.2, 0.3],\n",
    "                   [0.4, 0.5, 0.6]],\n",
    "                  \n",
    "                  [[0.1, 0.2, 0.3],\n",
    "                   [0.4, 0.5, 0.6]]])\n",
    "\n",
    "\n",
    "# 3,3,2\n",
    "# w.size = 4,2,3\n",
    "\n",
    "print(x.size(),W.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d5439",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m z = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(z.size())\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x,W)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2192b831",
   "metadata": {},
   "source": [
    "barch 차원이 3 != 4 (맞지않음)\n",
    "내적 계산은 맞으나 자동으로 batch가 브로드캐스팅 되지않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3e1778f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4000, 3.2000]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x,W.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b764b2bb",
   "metadata": {},
   "source": [
    "- 내적 차원 불일치 한 경우 : 불가\n",
    "- batch 차원이 맞지 않는데 브로드캐스팅 조건에도 맞지 않은 경우 : 불가\n",
    "- 내적 차원 일치 + batch 차원이 맞는 경우 : 가능\n",
    "- 내적 차원 일치 + batch 차원이 맞지 않는데, batch차원 브로드캐스팅 가능한 경우 : 가능 (자동 처리)\n",
    "=> batch는 행렬곱 연산 결과 자체에는 상관없으나, 형태가 맞아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c635e870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3,2)\n",
    "W = torch.randn(2,4,2)\n",
    "\n",
    "# y = torch.bmm(x, W.T)           # 3차원 이상은 transpose를 이용하여 명시적으로 교환해야 한다.\n",
    "y = torch.bmm(x, W.transpose(1,2)) # (2, 3, 2) @ (2, 2, 4) => (2, 3, 4)\n",
    "y.size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fcc397",
   "metadata": {},
   "source": [
    "transpose(dim1, dim2) : 지정된 2개의 차원을 교환\n",
    "(2, 4, 2) -> (2, 2, 4) : 내적 차원 계산할 수 있도록 전치\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d935dc5a",
   "metadata": {},
   "source": [
    "### nn.Linear를 활용하여 선형 연산 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee125409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "x = torch.FloatTensor([[1,2,3]]) # 1,3\n",
    "\n",
    "W = torch.FloatTensor([[0.1, 0.2, 0.3],\n",
    "                  [0.4, 0.5, 0.6]])  # 2,3\n",
    "\n",
    "print(x.size(), W.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca6d9da",
   "metadata": {},
   "source": [
    "nn.Linear 레이어 생성 (bias 생략) : 수동으로 만든 행렬곱과 정확히 동일한 결과가 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d85cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(\n",
    "    in_features = 3,           # 입력 벡터의 길이(x의 열), 행렬곱에서는 입력의 열 차원\n",
    "    out_features = 2,          # 출력 벡터의 길이(출력의 행)\n",
    "    bias = False               # bias 항 제외 -> 순수 행렬곱만 수행한 결과\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c5002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W를 nn.Linear 레이어에 직접 복사\n",
    "with torch.no_grad():           # 그레디언트 추적 비활성화 (가중치 수동 조절)\n",
    "    linear.weight.copy_(W)      # Linear 레이어의 가중치르 W값으로 직접 덮어쓰기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe5c6a1",
   "metadata": {},
   "source": [
    "```\n",
    "copy_(W) : 대입해주는 게 아니라 값만 복사\n",
    "=> 파라미터 객체는 그대로 유지\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b83eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4000, 3.2000]], grad_fn=<MmBackward0>) torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "y2 = linear(x)                  # 순전파 연산 (내부적으로는 행렬곱 계산만 진행)\n",
    "print(y2,y2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7253e55",
   "metadata": {},
   "source": [
    "linear(x) 연산을 했는데 내부적으로 자동으로 x @ W.T 시켜서 계산"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
